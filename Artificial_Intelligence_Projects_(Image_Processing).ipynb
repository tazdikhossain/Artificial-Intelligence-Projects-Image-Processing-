{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NsisFluCso_"
      },
      "outputs": [],
      "source": [
        "# Human Brain vs Neural network\n",
        "# Pixel-> convolution layer-> pooling layer-> Dense Layer-> Output layer\n",
        "# black and white -> 2D\n",
        "# Color image-> 3D (RGB)\n",
        "\n",
        "# Convolutional Layer -> convers picture into array\n",
        "# reduce the array to detect amd experiment the picture usinf filter\n",
        "\n",
        "# Convolutional Neural Network -> 1D array\n",
        "#1. Convolutional Layer\n",
        "#2. Relu\n",
        "#3. pooling layer\n",
        "#4. Fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3j4bbxHcsUy"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/t4pzwpvrzneb190/training_set.zip\n",
        "!wget https://www.dropbox.com/s/i37jfni3d29raoc/test_set.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YxYOJagWH_TG"
      },
      "outputs": [],
      "source": [
        "# Image Processing using python\n",
        "# Cat and Dog data set\n",
        "\n",
        "!unzip training_set.zip\n",
        "!unzip test_set.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY2kWf9kJh8G"
      },
      "outputs": [],
      "source": [
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "img = mpimg.imread('/content/test_set/test_set/cats/cat.4001.jpg')# any img url\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7BaIM75J7mW"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foB1XrRpLe5W"
      },
      "outputs": [],
      "source": [
        "# Desigining the model\n",
        "\n",
        "# Initialize the paramaters\n",
        "\n",
        "img_width, img_height = 150,150\n",
        "train_data_dir = r\"training\"\n",
        "validation_data_dir = r\"test\"\n",
        "nb_train_sample = 100\n",
        "nb_validation_sample = 100\n",
        "epochs = 20 # repeating a proper cycle\n",
        "batch_size = 20 # model will not learn from the whole dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gJCFsuWNHyf"
      },
      "outputs": [],
      "source": [
        "# Check the shape of the image\n",
        "\n",
        "# Two ways to represent the image data as a three dimention array\n",
        "# 1. Channel Last: Image data is represented in a three-dimentinal array where the last channel represent the color channels [rows][cols][channels]\n",
        "# 2. Channels first: Image data is represented in a three-dimention array where the first channel represents the color channels [channels][rows][cols]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViX7MtvScKeR"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as k\n",
        "if k.image_data_format()=='channels_first':\n",
        "  input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "  input_shape = (img_width, img_height,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsRqrSh5derl"
      },
      "source": [
        "#Generate image to train the model\n",
        "1. Rescale\n",
        "2. shear_range\n",
        "3. Zoom_range\n",
        "4. Horizontal_flip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F4fRaBrdsym",
        "outputId": "ad74bdfb-f89e-4156-e02c-aa26319f4d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# This class allows to configure random transformation and normaliation on the allocated image during training time\n",
        "# Prevents overfitting and helps to generate a generalize model\n",
        "# Never reprects the exact same images twice to train our model\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1. /255, shear_range = 0.2, zoom_range=0.2, horizontal_flip = True)\n",
        "validation_datagen = ImageDataGenerator(rescale=1. /255)\n",
        "\n",
        "#train_genarator = train_datagen.flow_from_directory(train_data_dir, target_size = (img_width, img_height), batch_size=batch_size, class_mode = 'binary', classes=['cat', 'dogs'])\n",
        "#validation_generator = validation_datagen.flow_from_directory(validation_data_dir, target_size = (img_width, img_height), batch_size = batch_size, class_mode='binary')\n",
        "# HOW this , will generate training generator data\n",
        "# Target_size = mentioned image_width, and image_height\n",
        "# Batch_size = 20(already mentioned)\n",
        "# Class_node = binary(because here only two classes are there to classify)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    classes=[\"cat\", \"dogs\"],\n",
        ")\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    classes=[\"cat\", \"dogs\"],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRti99FluLjM"
      },
      "outputs": [],
      "source": [
        "# Visual representation of ImageDataGenerator\n",
        "\n",
        "plt.figure(figure=(12,12))\n",
        "for i in range(0,15):\n",
        "  plt.subplot(5,3,i+1)\n",
        "  for X_batch, Y_batch in train_generator:\n",
        "    image = X_batch[0]\n",
        "    plt.inshow(image)\n",
        "    break\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP4IooL7vIZN"
      },
      "source": [
        "# Build the basic CNN model 0\n",
        "\n",
        "layers in CNN\n",
        "1. Convolutional Layer\n",
        "2. reLu\n",
        "3. Pooling Layer\n",
        "4. Fully Connected layer(Dense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2puxBhM_v6-D"
      },
      "outputs": [],
      "source": [
        "# Adding convolutonal neral network in the model\n",
        "# add() -> Helps to add layers in the model\n",
        "# Conv2D() -> Convolutonal layer(to extract features from the images)\n",
        "# Conv2D(32, (3,3)) input_shape= input_shape)\n",
        "# 32- take 32 features from the given images\n",
        "# (3,3) - Metrics size of the images(3*3)\n",
        "# input_shape = image_size\n",
        "\n",
        "# Activation function(relu) is added to remove the negative values\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64,(3,3), input_shape = input_shape)) #64 neurons with 3*3 filter\n",
        "#This class allows to create convolutional neural network to extract features from the images\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Maxpooling2D(pool_size=(2,2))) # MaxPooling2D helps to reduce the size of the data\n",
        "\n",
        "model.add(Flatten())# Converts multi dimentional array to 10 channel\n",
        "model.add(Dense(64))#64 neurons with 3*3 filter\n",
        "# numbers of output nodes in the hidden layers\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1)) #Output layer\n",
        "modela.add(Activation('sigmoid'))#sigmoid activation function\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mufjLaaBDcu"
      },
      "source": [
        "Compile the basic CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnD-v09ZBDEd"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'rnsprop', loss = 'binary_crossentropy', matrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poI9fbSgBr1f"
      },
      "source": [
        "Fit the basic CNN model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8rrs_KMBww2"
      },
      "outputs": [],
      "source": [
        "training = model.fit_generator(train-generator, steps_per_epoch-nb_train_sample, epoch-epochs, validation_data-validaton_generator, validation-steps-nb_validaton_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kox0YVO6DXKt"
      },
      "source": [
        "Find the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zy30j84DZ9f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# list all data in training\n",
        "print(training.history.key())\n",
        "\n",
        "#summarize training for accuracy\n",
        "plt.plot(training.history['accuracy'])\n",
        "plt.plot(training.history['val_acccuracy'])\n",
        "plt.title('model accuracy')\n",
        "\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test']), loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "#summarize training for loss\n",
        "plt.plot(training.history['loss'])\n",
        "plt.plot(training.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test']), loc = 'upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfHem5tRKrJE"
      },
      "outputs": [],
      "source": [
        "#predict the image\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "img_pred = image.load_img(\"\", target_size=(150,150))\n",
        "\n",
        "img_pred = image.img_to_array(img_pred)\n",
        "img_pred = np.expand_dims(img-pred, axis=0)\n",
        "\n",
        "rslt = model.predict(img_pred)\n",
        "print(rslt)\n",
        "if rslt [0][0]==1:\n",
        "  prediction = 'Dog'\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "  print('predict:', prediction)\n",
        "\n",
        "  img-mpimg.imread('')\n",
        "  implot = plt.imshow(img)\n",
        "  plt.show"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}